# -*- coding: utf-8 -*-
"""RoadSegmentation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vY-MVjARMZzvW1CudZa3upWpCvC-UFBd

# Creating Dataset with YOLO-Segmentation Model
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install ultralytics==8.0.196 opencv-python-headless

!pip install focal-loss segmentation-models-pytorch

"""The Following Code is for creating Dataset"""

# Upload the dataset with folder name input_images not using imagemet cause of data storage limit in colab

import os
from ultralytics import YOLO
import cv2

# Directories
input_dir = '/content/input_images'
segmented_output_dir = '/content/segmented_images_with_middle_points'
original_output_dir = '/content/original_images_with_middle_points'

# Create output directories if they don't exist
os.makedirs(segmented_output_dir, exist_ok=True)
os.makedirs(original_output_dir, exist_ok=True)

# Load the YOLO model
model = YOLO('yolov8s-seg.pt')

# Process each image in the input directory
for filename in os.listdir(input_dir):
    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):
        image_path = os.path.join(input_dir, filename)

        # Run inference
        results = model.predict(source=image_path, save=True)

        # Extract bounding boxes from results
        boxes = results[0].boxes

        # Load the segmented image saved by YOLO
        segmented_image_path = os.path.join('runs/segment/predict', filename)
        segmented_image = cv2.imread(segmented_image_path)

        # Load the original image
        original_image = cv2.imread(image_path)

        # Draw middle points on both images
        middle_points = []
        for box in boxes:
            # Extract coordinates and convert to integers
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            middle_point = ((x1 + x2) // 2, (y1 + y2) // 2)
            middle_points.append(middle_point)
            cv2.circle(segmented_image, middle_point, radius=5, color=(0, 255, 0), thickness=-1)  # Draw green dot on segmented image
            cv2.circle(original_image, middle_point, radius=5, color=(0, 255, 0), thickness=-1)   # Draw green dot on original image

        # Save the images with middle points
        segmented_output_path = os.path.join(segmented_output_dir, filename)
        original_output_path = os.path.join(original_output_dir, filename)
        cv2.imwrite(segmented_output_path, segmented_image)
        cv2.imwrite(original_output_path, original_image)

        # Optionally, print middle points coordinates
        print(f"Middle points for {filename}: {middle_points}")

print("Processing complete. Images saved to output directories.")



"""# Semi-supervised Training"""

# Install necessary libraries
import os
import cv2
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from ultralytics import YOLO
import numpy as np
from torchvision import transforms
from focal_loss import SparseCategoricalFocalLoss
from PIL import Image

# Directories
labeled_input_dir = '/content/input_images'
labeled_output_dir = '/content/outputs'
unlabeled_input_dir = '/content/unlabled'

# Create output directories if they don't exist
os.makedirs(labeled_output_dir, exist_ok=True)

# Load the YOLO model
model = YOLO('yolov8s-seg.pt')

# Data transformation
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.0, 0.0, 0.0], std=[1.0, 1.0, 1.0]),
    transforms.Resize((640, 640)),
])

def pCE_loss(output, mask):
    print("Output shape:", output.shape)
    print("Mask shape:", mask.shape)

    mask = mask.unsqueeze(1)  # Add a channel dimension to the mask
    focal_loss = SparseCategoricalFocalLoss(gamma=2)
    focal_loss_value = focal_loss(output, mask)
    masked_focal_loss = focal_loss_value * mask
    pCE = torch.sum(masked_focal_loss) / torch.sum(mask)
    return pCE


def pCE_loss(output, mask):
    mask = mask.unsqueeze(1)  # Add a channel dimension to the mask

    # Extract the class predictions from YOLO's output
    y_pred = output.pred[0]['class'].argmax(dim=1, keepdim=True)

    focal_loss = focal_loss.SparseCategoricalFocalLoss(gamma=2)  # Instantiate focal loss function
    loss = focal_loss(y_true=y_pred, y_pred=output.pred[0]['class'], from_logits=True)  # Compute focal loss

    return loss


# Load labeled data
labeled_images = [os.path.join(labeled_input_dir, f) for f in os.listdir(labeled_input_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
labeled_masks = [os.path.join(labeled_output_dir, f) for f in os.listdir(labeled_output_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

labeled_data = [(img, cv2.imread(mask, cv2.IMREAD_GRAYSCALE).astype(np.float32) / 255.0) for img, mask in zip(labeled_images, labeled_masks)]

# Load unlabeled data
unlabeled_images = [os.path.join(unlabeled_input_dir, f) for f in os.listdir(unlabeled_input_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

# Training parameters
n_epochs = 1
batch_size = 2

# Initialize model, optimizer, and loss function
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Initial training on labeled data
for epoch in range(n_epochs):
    model.train(epochs=n_epochs)
    for image_path, mask in labeled_data:
        image = cv2.imread(image_path)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        image = transform(image).unsqueeze(0)
        mask = torch.tensor(mask).unsqueeze(0)
        mask = torch.tensor(mask).unsqueeze(0) / 255.0


        optimizer.zero_grad()
        outputs = model(image)
        loss = pCE_loss(outputs, mask)
        loss.backward()
        optimizer.step()

# Pseudo-labeling on unlabeled data
model.eval()
with torch.no_grad():
    for image_path in unlabeled_images:
        image = cv2.imread(image_path)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        image = transform(image).unsqueeze(0)

        outputs = model(image)
        _, pseudo_label = torch.max(outputs, 1)
        pseudo_label = pseudo_label.squeeze(0).cpu().numpy()

        segmented_output_path = os.path.join(labeled_output_dir, os.path.basename(image_path))
        cv2.imwrite(segmented_output_path, pseudo_label)

# Load updated pseudo-labeled data
pseudo_labeled_data = [(img, cv2.imread(os.path.join(labeled_output_dir, os.path.basename(img)), cv2.IMREAD_GRAYSCALE)) for img in unlabeled_images]
labeled_data += pseudo_labeled_data

# Retrain the model with combined dataset
for epoch in range(n_epochs):
    model.train()
    for image_path, mask in labeled_data:
        image = cv2.imread(image_path)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        image = transform(image).unsqueeze(0)
        mask = torch.tensor(mask).unsqueeze(0)

        optimizer.zero_grad()
        outputs = model(image)
        loss = pCE_loss(outputs, mask)
        loss.backward()
        optimizer.step()

print("Processing complete. Model trained with semi-supervised learning.")